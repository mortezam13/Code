{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortezam13/mnist1/blob/main/nlptweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-21T13:58:59.819259Z",
          "iopub.execute_input": "2023-10-21T13:58:59.820279Z",
          "iopub.status.idle": "2023-10-21T13:58:59.841890Z",
          "shell.execute_reply.started": "2023-10-21T13:58:59.820238Z",
          "shell.execute_reply": "2023-10-21T13:58:59.840780Z"
        },
        "trusted": true,
        "id": "9BTIYu6gujEn",
        "outputId": "4cf2f1ad-4de3-4236-b708-fd4ed4870277"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:02.879657Z",
          "iopub.execute_input": "2023-10-21T13:59:02.881526Z",
          "iopub.status.idle": "2023-10-21T13:59:03.007735Z",
          "shell.execute_reply.started": "2023-10-21T13:59:02.881444Z",
          "shell.execute_reply": "2023-10-21T13:59:03.006721Z"
        },
        "trusted": true,
        "id": "k6Clsb3QujEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:06.312897Z",
          "iopub.execute_input": "2023-10-21T13:59:06.313519Z",
          "iopub.status.idle": "2023-10-21T13:59:06.339174Z",
          "shell.execute_reply.started": "2023-10-21T13:59:06.313468Z",
          "shell.execute_reply": "2023-10-21T13:59:06.337897Z"
        },
        "trusted": true,
        "id": "TnX0PnaxujEr",
        "outputId": "9c69a630-8feb-4409-bdd2-8b8b2b01a484"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    id keyword location  \\\n0    1     NaN      NaN   \n1    4     NaN      NaN   \n2    5     NaN      NaN   \n3    6     NaN      NaN   \n4    7     NaN      NaN   \n5    8     NaN      NaN   \n6   10     NaN      NaN   \n7   13     NaN      NaN   \n8   14     NaN      NaN   \n9   15     NaN      NaN   \n10  16     NaN      NaN   \n11  17     NaN      NaN   \n12  18     NaN      NaN   \n13  19     NaN      NaN   \n14  20     NaN      NaN   \n15  23     NaN      NaN   \n16  24     NaN      NaN   \n17  25     NaN      NaN   \n18  26     NaN      NaN   \n19  28     NaN      NaN   \n20  31     NaN      NaN   \n21  32     NaN      NaN   \n22  33     NaN      NaN   \n23  34     NaN      NaN   \n24  36     NaN      NaN   \n25  37     NaN      NaN   \n26  38     NaN      NaN   \n27  39     NaN      NaN   \n28  40     NaN      NaN   \n29  41     NaN      NaN   \n\n                                                                                                                                     text  \\\n0                                                                   Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n1                                                                                                  Forest fire near La Ronge Sask. Canada   \n2   All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n3                                                                       13,000 people receive #wildfires evacuation orders in California    \n4                                                Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n5                          #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires   \n6                                         #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas   \n7                                                                             I'm on top of the hill and I can see a fire in the woods...   \n8                                                         There's an emergency evacuation happening now in the building across the street   \n9                                                                                    I'm afraid that the tornado is coming to our area...   \n10                                                                                            Three people died from the heat wave so far   \n11      Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding   \n12                                                           #raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count    \n13                                                                                                #Flood in Bago Myanmar #We arrived Bago   \n14                                                                               Damage to school bus on 80 in multi car crash #BREAKING    \n15                                                                                                                         What's up man?   \n16                                                                                                                          I love fruits   \n17                                                                                                                       Summer is lovely   \n18                                                                                                                      My car is so fast   \n19                                                                                                           What a goooooooaaaaaal!!!!!!   \n20                                                                                                                 this is ridiculous....   \n21                                                                                                                      London is cool ;)   \n22                                                                                                                            Love skiing   \n23                                                                                                                  What a wonderful day!   \n24                                                                                                                               LOOOOOOL   \n25                                                                                                         No way...I can't eat that shit   \n26                                                                                                                  Was in NYC last week!   \n27                                                                                                                     Love my girlfriend   \n28                                                                                                                              Cooool :)   \n29                                                                                                                     Do you like pasta?   \n\n    target  \n0        1  \n1        1  \n2        1  \n3        1  \n4        1  \n5        1  \n6        1  \n7        1  \n8        1  \n9        1  \n10       1  \n11       1  \n12       1  \n13       1  \n14       1  \n15       0  \n16       0  \n17       0  \n18       0  \n19       0  \n20       0  \n21       0  \n22       0  \n23       0  \n24       0  \n25       0  \n26       0  \n27       0  \n28       0  \n29       0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation orders in California</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm on top of the hill and I can see a fire in the woods...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>There's an emergency evacuation happening now in the building across the street</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I'm afraid that the tornado is coming to our area...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Three people died from the heat wave so far</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Damage to school bus on 80 in multi car crash #BREAKING</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What's up man?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I love fruits</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer is lovely</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>My car is so fast</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What a goooooooaaaaaal!!!!!!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>this is ridiculous....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>London is cool ;)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Love skiing</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>What a wonderful day!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>36</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LOOOOOOL</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>No way...I can't eat that shit</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>38</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Was in NYC last week!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Love my girlfriend</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cooool :)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>41</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Do you like pasta?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "## let's get counts for the first 5 tweets in the data\n",
        "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n",
        "print(example_train_vectors[0].todense().shape)\n",
        "print(example_train_vectors[0].todense())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:24.705479Z",
          "iopub.execute_input": "2023-10-21T13:59:24.705956Z",
          "iopub.status.idle": "2023-10-21T13:59:24.722174Z",
          "shell.execute_reply.started": "2023-10-21T13:59:24.705922Z",
          "shell.execute_reply": "2023-10-21T13:59:24.720735Z"
        },
        "trusted": true,
        "id": "pZjlvneWujEs",
        "outputId": "46010c34-2f10-44a5-d097-7c70ed85607a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1, 54)\n[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
        "\n",
        "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
        "# that the tokens in the train vectors are the only ones mapped to the test vectors -\n",
        "# i.e. that the train and test vectors use the same set of tokens.\n",
        "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:26.522788Z",
          "iopub.execute_input": "2023-10-21T13:59:26.523345Z",
          "iopub.status.idle": "2023-10-21T13:59:26.926120Z",
          "shell.execute_reply.started": "2023-10-21T13:59:26.523297Z",
          "shell.execute_reply": "2023-10-21T13:59:26.924458Z"
        },
        "trusted": true,
        "id": "CGG2DzkFujEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = linear_model.RidgeClassifier()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:32.596006Z",
          "iopub.execute_input": "2023-10-21T13:59:32.596521Z",
          "iopub.status.idle": "2023-10-21T13:59:32.602759Z",
          "shell.execute_reply.started": "2023-10-21T13:59:32.596485Z",
          "shell.execute_reply": "2023-10-21T13:59:32.601205Z"
        },
        "trusted": true,
        "id": "_dhBRmUMujEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "scores\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:17:05.127503Z",
          "iopub.execute_input": "2023-10-21T13:17:05.128081Z",
          "iopub.status.idle": "2023-10-21T13:17:05.898274Z",
          "shell.execute_reply.started": "2023-10-21T13:17:05.128033Z",
          "shell.execute_reply": "2023-10-21T13:17:05.896472Z"
        },
        "trusted": true,
        "id": "PjV3ocmeujEs",
        "outputId": "0346ed8b-fc1a-498c-b090-aad9d94bf73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.59453669, 0.5642787 , 0.64082434])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:38.693711Z",
          "iopub.execute_input": "2023-10-21T13:59:38.694214Z",
          "iopub.status.idle": "2023-10-21T13:59:38.701718Z",
          "shell.execute_reply.started": "2023-10-21T13:59:38.694173Z",
          "shell.execute_reply": "2023-10-21T13:59:38.700367Z"
        },
        "trusted": true,
        "id": "FY3IfBCPujEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt =train_df['text'][0]\n",
        "txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:47.913528Z",
          "iopub.execute_input": "2023-10-21T13:59:47.914107Z",
          "iopub.status.idle": "2023-10-21T13:59:47.935366Z",
          "shell.execute_reply.started": "2023-10-21T13:59:47.914061Z",
          "shell.execute_reply": "2023-10-21T13:59:47.933982Z"
        },
        "trusted": true,
        "id": "LQIOdUGMujEt",
        "outputId": "62cdaefa-c41f-4a37-a8c1-666894c220b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:50.214212Z",
          "iopub.execute_input": "2023-10-21T13:59:50.215367Z",
          "iopub.status.idle": "2023-10-21T13:59:50.535252Z",
          "shell.execute_reply.started": "2023-10-21T13:59:50.215322Z",
          "shell.execute_reply": "2023-10-21T13:59:50.534142Z"
        },
        "trusted": true,
        "id": "Tp2A8k_cujEu",
        "outputId": "b4473763-72fc-4824-8f01-8120ee5ff7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(#14) ['Our','Deeds','are','the','Reason','of','this','#','earthquake','May'...]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts = train_df['text'][:2000]\n",
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txt]))[:40])\n",
        "subword(10000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T13:59:56.151512Z",
          "iopub.execute_input": "2023-10-21T13:59:56.152058Z",
          "iopub.status.idle": "2023-10-21T13:59:56.582557Z",
          "shell.execute_reply.started": "2023-10-21T13:59:56.152017Z",
          "shell.execute_reply": "2023-10-21T13:59:56.581428Z"
        },
        "trusted": true,
        "id": "9RmhHRR-ujEv",
        "outputId": "cfd9ae40-8c99-4c89-a3e4-c2993f6da9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'▁Our ▁De ed s ▁are ▁the ▁Reason ▁of ▁this ▁# earth qu ake ▁May ▁ALL AH ▁For give ▁us ▁all'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "toks_n=train_df['text'].map(tkn)\n",
        "toks_n[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:00:00.578011Z",
          "iopub.execute_input": "2023-10-21T14:00:00.578628Z",
          "iopub.status.idle": "2023-10-21T14:00:09.642815Z",
          "shell.execute_reply.started": "2023-10-21T14:00:00.578569Z",
          "shell.execute_reply": "2023-10-21T14:00:09.641525Z"
        },
        "trusted": true,
        "id": "e08gSVroujEw",
        "outputId": "cd7d45ea-6ff4-4773-f091-e1996d2ff67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(#21) ['xxbos','xxmaj','our','xxmaj','deeds','are','the','xxmaj','reason','of'...]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks_n)\n",
        "coll_repr(num.vocab)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:00:12.839339Z",
          "iopub.execute_input": "2023-10-21T14:00:12.840732Z",
          "iopub.status.idle": "2023-10-21T14:00:12.929845Z",
          "shell.execute_reply.started": "2023-10-21T14:00:12.840672Z",
          "shell.execute_reply": "2023-10-21T14:00:12.928818Z"
        },
        "trusted": true,
        "id": "-6z9gLTNujEw",
        "outputId": "93f39036-b6a8-489b-f3df-b08567d27e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"(#4568) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','/'...]\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_a=toks_n.map(num)\n",
        "dl = LMDataLoader(num_a)\n",
        "x,y = first(dl)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:00:18.745692Z",
          "iopub.execute_input": "2023-10-21T14:00:18.746540Z",
          "iopub.status.idle": "2023-10-21T14:00:20.532936Z",
          "shell.execute_reply.started": "2023-10-21T14:00:18.746499Z",
          "shell.execute_reply": "2023-10-21T14:00:20.531324Z"
        },
        "trusted": true,
        "id": "NAOgr1n3ujEw",
        "outputId": "32b79617-8d36-4421-d7ba-400bd5045be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(torch.Size([64, 72]), torch.Size([64, 72]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(num.vocab[o] for o in x[0][:20])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:00:23.809937Z",
          "iopub.execute_input": "2023-10-21T14:00:23.810431Z",
          "iopub.status.idle": "2023-10-21T14:00:23.821473Z",
          "shell.execute_reply.started": "2023-10-21T14:00:23.810362Z",
          "shell.execute_reply": "2023-10-21T14:00:23.820162Z"
        },
        "trusted": true,
        "id": "PUeYPyk1ujEx",
        "outputId": "06d8686b-ab78-4a8c-a903-aa933fcc5b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'xxbos xxmaj our xxmaj xxunk are the xxmaj reason of this # earthquake xxmaj may xxup allah xxmaj xxunk us'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(num.vocab[o] for o in y[0][:20])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:00:30.233664Z",
          "iopub.execute_input": "2023-10-21T14:00:30.234599Z",
          "iopub.status.idle": "2023-10-21T14:00:30.247617Z",
          "shell.execute_reply.started": "2023-10-21T14:00:30.234534Z",
          "shell.execute_reply": "2023-10-21T14:00:30.245508Z"
        },
        "trusted": true,
        "id": "Di287n6PujEy",
        "outputId": "beda594e-56e2-4d44-ddd5-b761b30360ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'xxmaj our xxmaj xxunk are the xxmaj reason of this # earthquake xxmaj may xxup allah xxmaj xxunk us all'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "src_path = r\"/kaggle/input/nlp-getting-started/test.csv\"\n",
        "dst_path = r\"/kaggle/working/\"\n",
        "shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:39:35.624760Z",
          "iopub.execute_input": "2023-10-21T14:39:35.625218Z",
          "iopub.status.idle": "2023-10-21T14:39:35.638764Z",
          "shell.execute_reply.started": "2023-10-21T14:39:35.625187Z",
          "shell.execute_reply": "2023-10-21T14:39:35.637223Z"
        },
        "trusted": true,
        "id": "YiEXsVA1ujEy",
        "outputId": "ff532c8a-82b2-4491-c7d2-24e1a9959a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 52,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/test.csv'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_path = r\"/kaggle/input/nlp-getting-started/train.csv\"\n",
        "dst_path = r\"/kaggle/working/\"\n",
        "shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:40:25.816519Z",
          "iopub.execute_input": "2023-10-21T14:40:25.816975Z",
          "iopub.status.idle": "2023-10-21T14:40:25.834159Z",
          "shell.execute_reply.started": "2023-10-21T14:40:25.816939Z",
          "shell.execute_reply": "2023-10-21T14:40:25.832712Z"
        },
        "trusted": true,
        "id": "IdxhmSfwujEy",
        "outputId": "268c0070-c8f7-4d49-ba03-75ebdc00fe5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 53,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/train.csv'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=r'/kaggle/working/train.csv'\n",
        "files = get_text_files(path, folders = ['train', 'test'])\n",
        "get_tweets = partial(get_text_files, folders=['train', 'test'])\n",
        "dls_lm = DataBlock(\n",
        "blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "get_items=get_tweets, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path, path=path, bs=128, seq_len=80)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-21T14:47:52.084136Z",
          "iopub.execute_input": "2023-10-21T14:47:52.084605Z",
          "iopub.status.idle": "2023-10-21T14:47:52.625059Z",
          "shell.execute_reply.started": "2023-10-21T14:47:52.084567Z",
          "shell.execute_reply": "2023-10-21T14:47:52.622978Z"
        },
        "trusted": true,
        "id": "bkYs6ku4ujEz",
        "outputId": "f41ec535-0e24-4870-c87d-a6b66a36e9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m files \u001b[38;5;241m=\u001b[39m get_text_files(path, folders \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m get_tweets \u001b[38;5;241m=\u001b[39m partial(get_text_files, folders\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m dls_lm \u001b[38;5;241m=\u001b[39m \u001b[43mDataBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43mblocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTextBlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_lm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43mget_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_tweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomSplitter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/block.py:155\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataloaders\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    150\u001b[0m     source, \u001b[38;5;66;03m# The data source\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     path:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Data source and default `Learner` path \u001b[39;00m\n\u001b[1;32m    152\u001b[0m     verbose:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Show verbose messages\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataLoaders:\n\u001b[0;32m--> 155\u001b[0m     dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/block.py:147\u001b[0m, in \u001b[0;36mDataBlock.datasets\u001b[0;34m(self, source, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m splits \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter \u001b[38;5;129;01mor\u001b[39;00m RandomSplitter())(items)\n\u001b[1;32m    146\u001b[0m pv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(splits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datasets of sizes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s))\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39msplits])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verbose)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_type_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdl_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_inp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/core.py:454\u001b[0m, in \u001b[0;36mDatasets.__init__\u001b[0;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    446\u001b[0m     items:\u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     tfms:MutableSequence\u001b[38;5;241m|\u001b[39mPipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    452\u001b[0m ):\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dl_type\u001b[38;5;241m=\u001b[39mdl_type)\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls \u001b[38;5;241m=\u001b[39m L(tls \u001b[38;5;28;01mif\u001b[39;00m tls \u001b[38;5;28;01melse\u001b[39;00m [TfmdLists(items, t, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m L(ifnone(tfms,[\u001b[38;5;28;01mNone\u001b[39;00m]))])\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inp \u001b[38;5;241m=\u001b[39m ifnone(n_inp, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/core.py:454\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    446\u001b[0m     items:\u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     tfms:MutableSequence\u001b[38;5;241m|\u001b[39mPipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    452\u001b[0m ):\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dl_type\u001b[38;5;241m=\u001b[39mdl_type)\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls \u001b[38;5;241m=\u001b[39m L(tls \u001b[38;5;28;01mif\u001b[39;00m tls \u001b[38;5;28;01melse\u001b[39;00m [\u001b[43mTfmdLists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m L(ifnone(tfms,[\u001b[38;5;28;01mNone\u001b[39;00m]))])\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inp \u001b[38;5;241m=\u001b[39m ifnone(n_inp, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastcore/foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mcls\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/core.py:368\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[0;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_setup:\n\u001b[1;32m    367\u001b[0m     pv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting up \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verbose)\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_setup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_setup\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fastai/data/core.py:397\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[0;34m(self, train_setup)\u001b[0m\n\u001b[1;32m    395\u001b[0m         x \u001b[38;5;241m=\u001b[39m f(x)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[0;32m--> 397\u001b[0m types \u001b[38;5;241m=\u001b[39m L(t \u001b[38;5;28;01mif\u001b[39;00m is_listy(t) \u001b[38;5;28;01melse\u001b[39;00m [t] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes)\u001b[38;5;241m.\u001b[39mconcat()\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretty_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types])\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ],
          "ename": "TypeError",
          "evalue": "'NoneType' object is not iterable",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.fast.ai/tutorial.datablock.html\n",
        "https://docs.fast.ai/text.data.html#textblock\n",
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "dls_lm = DataBlock(\n",
        "blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path, path=path, bs=128, seq_len=80)\n",
        "https://dirk-kalmbach.medium.com/datablock-and-dataloaders-in-fastai-d5aa7ae560e5"
      ],
      "metadata": {
        "id": "hxH-YaSjujEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_d.show_batch(max_n=8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-17T08:16:10.750213Z",
          "iopub.execute_input": "2023-10-17T08:16:10.750726Z",
          "iopub.status.idle": "2023-10-17T08:16:11.138383Z",
          "shell.execute_reply.started": "2023-10-17T08:16:10.750680Z",
          "shell.execute_reply": "2023-10-17T08:16:11.137176Z"
        },
        "trusted": true,
        "id": "dUcw33gKujE0",
        "outputId": "0016227d-334e-41bc-e11d-f243dfd2a877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos i was over here xxunk xxunk then that loud ass thunder wanted to xxunk me . ? ? xxbos xxmaj new xxup isis xxmaj video : xxup isis xxmaj threatens to xxmaj xxunk xxmaj croatian xxmaj hostage xxmaj within 48 xxmaj hours - xxunk - xxunk # auspol http : / / t.co / xxunk xxbos xxmaj final # xxmaj xxunk update : shot a xxunk . xxunk on front ( exploded with a ) xxunk on back .</td>\n      <td>i was over here xxunk xxunk then that loud ass thunder wanted to xxunk me . ? ? xxbos xxmaj new xxup isis xxmaj video : xxup isis xxmaj threatens to xxmaj xxunk xxmaj croatian xxmaj hostage xxmaj within 48 xxmaj hours - xxunk - xxunk # auspol http : / / t.co / xxunk xxbos xxmaj final # xxmaj xxunk update : shot a xxunk . xxunk on front ( exploded with a ) xxunk on back . #</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>old boy has been charged with manslaughter over the fatal sh … xxbos xxmaj my xxunk going to explode i need to leave this house . xxmaj ill be out smoking packs if you need me xxbos xxmaj cute &amp; &amp; all xxunk ' the life then you xxunk in on one 's face and you have a meme ready : ' i 've seen the xxmaj gates of xxmaj hell and survived ' xxbos xxmaj hellfire ! xxmaj we</td>\n      <td>boy has been charged with manslaughter over the fatal sh … xxbos xxmaj my xxunk going to explode i need to leave this house . xxmaj ill be out smoking packs if you need me xxbos xxmaj cute &amp; &amp; all xxunk ' the life then you xxunk in on one 's face and you have a meme ready : ' i 've seen the xxmaj gates of xxmaj hell and survived ' xxbos xxmaj hellfire ! xxmaj we donûªt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/ xxunk xxbos xxmaj just realized my dude xxunk was on that ' what xxmaj are xxmaj those ' way before it blew up @ the xxunk ? ? game xxunk xxunk xxbos xxmaj patience xxmaj jonathan xxmaj on xxmaj the xxmaj move xxmaj to xxmaj hijack xxup apc xxmaj in xxmaj bayelsa xxmaj state http : / / t.co / xxunk http : / / t.co / xxunk xxbos i could demolish this right now ! https : /</td>\n      <td>xxunk xxbos xxmaj just realized my dude xxunk was on that ' what xxmaj are xxmaj those ' way before it blew up @ the xxunk ? ? game xxunk xxunk xxbos xxmaj patience xxmaj jonathan xxmaj on xxmaj the xxmaj move xxmaj to xxmaj hijack xxup apc xxmaj in xxmaj bayelsa xxmaj state http : / / t.co / xxunk http : / / t.co / xxunk xxbos i could demolish this right now ! https : / /</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i electrocute you xxup too xxunk right ? ' xxbos xxmaj brian xxmaj xxunk + xxup xxunk . xxmaj xxunk + xxmaj xxunk xxmaj xxunk trying to defend xxunk xxmaj xxunk was a xxup blood xxup volcano http : / / t.co / xxunk xxbos . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : .</td>\n      <td>electrocute you xxup too xxunk right ? ' xxbos xxmaj brian xxmaj xxunk + xxup xxunk . xxmaj xxunk + xxmaj xxunk xxmaj xxunk trying to defend xxunk xxmaj xxunk was a xxup blood xxup volcano http : / / t.co / xxunk xxbos . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . :</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/ xxunk xxbos xxmaj bigamist and his ' first ' wife are charged in the deaths of his ' second ' pregnant wife her child 8 her … http : / / t.co / xxunk # news xxbos @raynbowaffair xxmaj editor xxmaj in xxmaj chief @diamondkesawn xxmaj releases xxmaj issue # 7 http : / / t.co / xxunk of # ramag . # xxmaj fashion # xxmaj models and # xxmaj mayhem xxbos xxmaj i 'm about to be</td>\n      <td>xxunk xxbos xxmaj bigamist and his ' first ' wife are charged in the deaths of his ' second ' pregnant wife her child 8 her … http : / / t.co / xxunk # news xxbos @raynbowaffair xxmaj editor xxmaj in xxmaj chief @diamondkesawn xxmaj releases xxmaj issue # 7 http : / / t.co / xxunk of # ramag . # xxmaj fashion # xxmaj models and # xxmaj mayhem xxbos xxmaj i 'm about to be obliterated</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>checked it out :-) https : / / t.co / xxunk xxbos xxmaj that 's the ultimate road to destruction xxbos xxmaj by the grace of xxup god i survived the 2 am shift and i m not that tired . xxbos xxup cnn xxmaj news xxmaj august 5 2015 xxmaj two trains derailed amid floods … \\n xxmaj video for india august flooding 2015 video youtube ? … http : / / t.co / xxunk xxbos xxmaj the xxmaj</td>\n      <td>it out :-) https : / / t.co / xxunk xxbos xxmaj that 's the ultimate road to destruction xxbos xxmaj by the grace of xxup god i survived the 2 am shift and i m not that tired . xxbos xxup cnn xxmaj news xxmaj august 5 2015 xxmaj two trains derailed amid floods … \\n xxmaj video for india august flooding 2015 video youtube ? … http : / / t.co / xxunk xxbos xxmaj the xxmaj campaign</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>truth … \\n https : / / t.co / xxunk \\n▁ # xxmaj news \\n▁ # xxup bbc \\n▁ # xxup cnn \\n▁ # xxmaj islam \\n▁ # xxmaj truth \\n▁ # god \\n▁ # xxup isis \\n▁ # terrorism \\n▁ # xxmaj quran \\n▁ # xxmaj lies http : / / t.co / xxunk xxbos xxunk lets get a xxunk picture together and have the xxunk explosion xxrep 4 ? xxbos xxunk haha traumatised xxrep 4 ! xxmaj hell</td>\n      <td>… \\n https : / / t.co / xxunk \\n▁ # xxmaj news \\n▁ # xxup bbc \\n▁ # xxup cnn \\n▁ # xxmaj islam \\n▁ # xxmaj truth \\n▁ # god \\n▁ # xxup isis \\n▁ # terrorism \\n▁ # xxmaj quran \\n▁ # xxmaj lies http : / / t.co / xxunk xxbos xxunk lets get a xxunk picture together and have the xxunk explosion xxrep 4 ? xxbos xxunk haha traumatised xxrep 4 ! xxmaj hell no</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>flying so low my xxunk is shaking ! xxbos going to xxunk my xxunk and watch behind the xxunk of desolation of smaug a xxrep 3 y xxbos i just screamed what the fuck is a xxunk xxbos xxmaj evacuation order lifted for town of xxmaj roosevelt xxmaj wash . though residents warned to be ready to leave quickly http : / / t.co / xxunk xxbos a xxup xxunk satellite ' xxunk ' in xxmaj typhoon xxmaj soudelor http</td>\n      <td>so low my xxunk is shaking ! xxbos going to xxunk my xxunk and watch behind the xxunk of desolation of smaug a xxrep 3 y xxbos i just screamed what the fuck is a xxunk xxbos xxmaj evacuation order lifted for town of xxmaj roosevelt xxmaj wash . though residents warned to be ready to leave quickly http : / / t.co / xxunk xxbos a xxup xxunk satellite ' xxunk ' in xxmaj typhoon xxmaj soudelor http :</td>\n    </tr>\n  </tbody>\n</table>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dls_clas = DataBlock(\n",
        "blocks=(TextBlock.from_df('text', vocab=train_d.vocab),CategoryBlock),\n",
        "get_y = parent_label,get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path, path=path, bs=128, seq_len=72)"
      ],
      "metadata": {
        "id": "MMByBm1DujE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}